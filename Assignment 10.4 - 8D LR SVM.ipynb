{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Assignment 10.4</font> : 8D LR SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86Tvnj5UblTy"
   },
   "source": [
    "## <font color='red'>Task-D</font> : Collinear features and their effect on linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qn_eOn2EblT3"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMoYWIayblUB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfStXG4tblUI",
    "outputId": "ddf4eec6-7f53-4d28-914f-23133957d6d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.581066</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.604025</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-0.665927</td>\n",
       "      <td>-0.536277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.894309</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.883052</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-0.917054</td>\n",
       "      <td>-0.522364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.207552</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.082312</td>\n",
       "      <td>-1.150918</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.166507</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364174</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.943643</td>\n",
       "      <td>-1.280666</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-1.266540</td>\n",
       "      <td>-0.665720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737687</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.744934</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-0.792746</td>\n",
       "      <td>-0.735054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z       x*x       2*y  2*z+3*x*x         w  \\\n",
       "0 -0.581066  0.841837 -1.012978 -0.604025  0.841837  -0.665927 -0.536277   \n",
       "1 -0.894309 -0.207835 -1.012978 -0.883052 -0.207835  -0.917054 -0.522364   \n",
       "2 -1.207552  0.212034 -1.082312 -1.150918  0.212034  -1.166507  0.205738   \n",
       "3 -1.364174  0.002099 -0.943643 -1.280666  0.002099  -1.266540 -0.665720   \n",
       "4 -0.737687  1.051772 -1.012978 -0.744934  1.051772  -0.792746 -0.735054   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIIuomCkblUP"
   },
   "outputs": [],
   "source": [
    "X = data.drop(['target'], axis=1).values\n",
    "Y = data['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ydm98u3EblUU"
   },
   "source": [
    "### Doing perturbation test to check the presence of collinearity  \n",
    "\n",
    "#### Task: 1 Logistic Regression\n",
    "<pre>\n",
    "\n",
    "\n",
    "1. <b>Finding the Correlation between the features</b>\n",
    "    a. check the correlation between the features\n",
    "    b. plot heat map of correlation matrix using seaborn heatmap\n",
    "2. <b>Finding the best model for the given data</b>\n",
    "    a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         \n",
    "    random search CV make sure you choose the alpha in log space)\n",
    "    c. Creat a new Logistic regression with the best alpha\n",
    "    (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "    \n",
    "3. <b>Getting the weights with the original data</b>\n",
    "    a. train the 'best_model' with X, Y\n",
    "    b. Check the accuracy of the model 'best_model_accuracy'\n",
    "    c. Get the weights W using best_model.coef_\n",
    "\n",
    "4. <b>Modifying original data</b>\n",
    "    a. Add a noise(order of 10^-2) to each element of X \n",
    "    and get the new data set X' (X' = X + e)\n",
    "    b. Train the same 'best_model' with data (X', Y)\n",
    "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "    d. Get the weights W' using best_model.coef_\n",
    "    \n",
    "5. <b> Checking deviations in metric and weights </b>\n",
    "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "    c. print the top 4 features which have higher % change in weights \n",
    "    compare to the other feature\n",
    "\n",
    "</pre>\n",
    "\n",
    "#### Task: 2 Linear SVM\n",
    "\n",
    "<pre>\n",
    "1. Do the same steps (2, 3, 4, 5) we have done in the above task 1.\n",
    "</pre>\n",
    "\n",
    "<strong><font color='red'>Do write the observations based on the results you get from the deviations of weights in both Logistic Regression and linear SVM</font></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lai8wXU1pmSb"
   },
   "source": [
    "## Doing perturbation test to check the presence of collinearity\n",
    "## <font color='red'>Task 1.</font> :  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>1. Finding the Correlation between the features : </font>\n",
    "\n",
    "a. check the correlation between the features.\n",
    "\n",
    "b. plot heat map of correlation matrix using seaborn heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.205926</td>\n",
       "      <td>0.812458</td>\n",
       "      <td>0.997947</td>\n",
       "      <td>-0.205926</td>\n",
       "      <td>0.996252</td>\n",
       "      <td>0.583277</td>\n",
       "      <td>0.728290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>-0.205926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>-0.690684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.812458</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807137</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>0.847163</td>\n",
       "      <td>0.674486</td>\n",
       "      <td>0.969990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x*x</th>\n",
       "      <td>0.997947</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>0.807137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>0.583803</td>\n",
       "      <td>0.719570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2*y</th>\n",
       "      <td>-0.205926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>-0.690684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <td>0.996252</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>0.847163</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606860</td>\n",
       "      <td>0.764729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0.583277</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>0.674486</td>\n",
       "      <td>0.583803</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>0.606860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.728290</td>\n",
       "      <td>-0.690684</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.719570</td>\n",
       "      <td>-0.690684</td>\n",
       "      <td>0.764729</td>\n",
       "      <td>0.641750</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x         y         z       x*x       2*y  2*z+3*x*x  \\\n",
       "x          1.000000 -0.205926  0.812458  0.997947 -0.205926   0.996252   \n",
       "y         -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123   \n",
       "z          0.812458 -0.602663  1.000000  0.807137 -0.602663   0.847163   \n",
       "x*x        0.997947 -0.209289  0.807137  1.000000 -0.209289   0.997457   \n",
       "2*y       -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123   \n",
       "2*z+3*x*x  0.996252 -0.261123  0.847163  0.997457 -0.261123   1.000000   \n",
       "w          0.583277 -0.401790  0.674486  0.583803 -0.401790   0.606860   \n",
       "target     0.728290 -0.690684  0.969990  0.719570 -0.690684   0.764729   \n",
       "\n",
       "                  w    target  \n",
       "x          0.583277  0.728290  \n",
       "y         -0.401790 -0.690684  \n",
       "z          0.674486  0.969990  \n",
       "x*x        0.583803  0.719570  \n",
       "2*y       -0.401790 -0.690684  \n",
       "2*z+3*x*x  0.606860  0.764729  \n",
       "w          1.000000  0.641750  \n",
       "target     0.641750  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_corr = data.corr()\n",
    "data_htmp = sns.heatmap(data_corr)\n",
    "data_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Observation : </font>\n",
    "From Above heatmap we can say that after slightly change in original features are not most affected in correations because in above heatmap show digonal element are correlated as we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>2. Finding the best model for the given data</font>\n",
    "a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "\n",
    "b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)\n",
    "\n",
    "c. Creat a new Logistic regression with the best alpha (search for how to get the best hyper parameter value), name the best model as 'best_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_LR = SGDClassifier(loss = 'log', random_state = 10)\n",
    "alphas = {\"alpha\" : [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000, 10000]}\n",
    "G_S_CV = GridSearchCV(SGD_LR, alphas, cv = 5)\n",
    "G_S_CV.fit(X, Y)\n",
    "G_S_CV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>3. Getting the weights with the original data</font>\n",
    "a. train the 'best_model' with X, Y\n",
    "\n",
    "b. Check the accuracy of the model 'best_model_accuracy'\n",
    "\n",
    "c. Get the weights W using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SGDClassifier(loss = 'log', alpha = 0.0001)\n",
    "best_model.fit(X, Y)\n",
    "y_predict = best_model.predict(X)\n",
    "best_model_accuracy = accuracy_score(Y, y_predict)\n",
    "best_model_coef = best_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>4. Modifying original data</font>\n",
    "a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)\n",
    "\n",
    "b. Train the same 'best_model' with data (X', Y)\n",
    "\n",
    "c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "\n",
    "d. Get the weights W' using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dash = X + 0.01\n",
    "best_model.fit(X_dash, Y)\n",
    "y_predict = best_model.predict(X_dash)\n",
    "best_model_accuracy_edited = accuracy_score(Y, y_predict)\n",
    "best_model_coef_edited = best_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>5.  Checking deviations in metric and weights</font> \n",
    "a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "\n",
    "b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "\n",
    "c. print the top 4 features which have higher % change in weights compare to the other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* Difference Between \"best_model_accuracy_edited\" and \"best_model_accuracy\" **************************\n",
      "Original Accuracy :  1.0\n",
      "Edited Accuracy :  1.0\n",
      "Difference Between Accuracy :  0.0\n",
      "\n",
      "\n",
      "*********************************** Difference Between each value of W and W' ==> |(W-W')| ***********************************\n",
      "Original Weight W :  \n",
      "\n",
      "[[ 2.65319829 -2.22040923  4.82933037  2.56549431 -2.22040923  2.89202416\n",
      "   2.17624176]] \n",
      "\n",
      "Edited Weight W' :  \n",
      "\n",
      "[[  7.94210023 -13.35595253  18.78575286   7.43415836 -13.35595253\n",
      "    8.9605492    1.37051688]] \n",
      "\n",
      "Difference Between Weights |(W-W')| :  \n",
      "\n",
      "[[ 5.28890194 11.13554329 13.95642248  4.86866405 11.13554329  6.06852504\n",
      "   0.80572488]]\n",
      "\n",
      "\n",
      "********************** Top 4 features which have higher % change in weights compare to the other feature **********************\n",
      "z\n",
      "y\n",
      "2*y\n",
      "2*z+3*x*x\n"
     ]
    }
   ],
   "source": [
    "print('*'*25, 'Difference Between \"best_model_accuracy_edited\" and \"best_model_accuracy\"', '*'*26)\n",
    "print(\"Original Accuracy : \", best_model_accuracy)\n",
    "print(\"Edited Accuracy : \", best_model_accuracy_edited)\n",
    "print(\"Difference Between Accuracy : \", best_model_accuracy-best_model_accuracy_edited)\n",
    "print('\\n')\n",
    "print('*'*35, \"Difference Between each value of W and W' ==> |(W-W')|\", '*'*35)\n",
    "print(\"Original Weight W : \", '\\n')\n",
    "print(best_model_coef, '\\n')\n",
    "print(\"Edited Weight W' : \", '\\n')\n",
    "print(best_model_coef_edited, '\\n')\n",
    "print(\"Difference Between Weights |(W-W')| : \", '\\n' )\n",
    "change_in_weight = np.abs(best_model_coef-best_model_coef_edited)\n",
    "print(change_in_weight)\n",
    "print('\\n')\n",
    "print('*'*22, \"Top 4 features which have higher % change in weights compare to the other feature\", '*'*22)\n",
    "data_columns = list(data.columns)\n",
    "for indx in np.argsort(-change_in_weight).reshape(-1)[:4]:\n",
    "    print(data_columns[indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Observation : </font>\n",
    "From our observation about the above code output we can say weight affected when we add noise to our dataset and weight changes drastically, and it indicate multicolinearity. But most important thing is our model does not affected due to multicolinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Task 2.</font> :  Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>2. Finding the best model for the given data</font>\n",
    "a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "\n",
    "b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)\n",
    "\n",
    "c. Creat a new Logistic regression with the best alpha (search for how to get the best hyper parameter value), name the best model as 'best_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-05}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Linear_SVM = SGDClassifier(loss = 'hinge', random_state = 10)\n",
    "alphas = {\"alpha\" : [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000, 10000]}\n",
    "G_S_CV = GridSearchCV(Linear_SVM, alphas, cv = 5)\n",
    "G_S_CV.fit(X, Y)\n",
    "G_S_CV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>3. Getting the weights with the original data</font>\n",
    "a. train the 'best_model' with X, Y\n",
    "\n",
    "b. Check the accuracy of the model 'best_model_accuracy'\n",
    "\n",
    "c. Get the weights W using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SGDClassifier(loss = 'log', alpha = 0.0001)\n",
    "best_model.fit(X, Y)\n",
    "y_predict = best_model.predict(X)\n",
    "best_model_accuracy = accuracy_score(Y, y_predict)\n",
    "best_model_coef = best_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>4. Modifying original data</font>\n",
    "a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)\n",
    "\n",
    "b. Train the same 'best_model' with data (X', Y)\n",
    "\n",
    "c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "\n",
    "d. Get the weights W' using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dash = X + 0.01\n",
    "best_model.fit(X_dash, Y)\n",
    "y_predict = best_model.predict(X_dash)\n",
    "best_model_accuracy_edited = accuracy_score(Y, y_predict)\n",
    "best_model_coef_edited = best_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>5.  Checking deviations in metric and weights</font> \n",
    "a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "\n",
    "b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "\n",
    "c. print the top 4 features which have higher % change in weights compare to the other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* Difference Between \"best_model_accuracy_edited\" and \"best_model_accuracy\" **************************\n",
      "Original Accuracy :  1.0\n",
      "Edited Accuracy :  1.0\n",
      "Difference Between Accuracy :  0.0\n",
      "\n",
      "\n",
      "*********************************** Difference Between each value of W and W' ==> |(W-W')| ***********************************\n",
      "Original Weight W :  \n",
      "\n",
      "[[ 9.64292925 -8.82881754 23.46015273  7.66011038 -8.82881754  9.72656539\n",
      "   0.13075164]] \n",
      "\n",
      "Edited Weight W' :  \n",
      "\n",
      "[[ 1.62947151 -1.56986035  5.63660332  1.46021686 -1.56986035  1.99449499\n",
      "   2.32487842]] \n",
      "\n",
      "Difference Between Weights |(W-W')| :  \n",
      "\n",
      "[[ 8.01345774  7.25895719 17.82354942  6.19989352  7.25895719  7.73207039\n",
      "   2.19412678]]\n",
      "\n",
      "\n",
      "********************** Top 4 features which have higher % change in weights compare to the other feature **********************\n",
      "z\n",
      "x\n",
      "2*z+3*x*x\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "print('*'*25, 'Difference Between \"best_model_accuracy_edited\" and \"best_model_accuracy\"', '*'*26)\n",
    "print(\"Original Accuracy : \", best_model_accuracy)\n",
    "print(\"Edited Accuracy : \", best_model_accuracy_edited)\n",
    "print(\"Difference Between Accuracy : \", best_model_accuracy-best_model_accuracy_edited)\n",
    "print('\\n')\n",
    "print('*'*35, \"Difference Between each value of W and W' ==> |(W-W')|\", '*'*35)\n",
    "print(\"Original Weight W : \", '\\n')\n",
    "print(best_model_coef, '\\n')\n",
    "print(\"Edited Weight W' : \", '\\n')\n",
    "print(best_model_coef_edited, '\\n')\n",
    "print(\"Difference Between Weights |(W-W')| : \", '\\n' )\n",
    "change_in_weight = (np.abs(best_model_coef-best_model_coef_edited))\n",
    "print(change_in_weight)\n",
    "print('\\n')\n",
    "print('*'*22, \"Top 4 features which have higher % change in weights compare to the other feature\", '*'*22)\n",
    "data_columns = list(data.columns)\n",
    "for indx in np.argsort(-change_in_weight).reshape(-1)[:4]:\n",
    "    print(data_columns[indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Observation : </font>\n",
    "We conclude same for Linear SVM as above."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "8D_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
