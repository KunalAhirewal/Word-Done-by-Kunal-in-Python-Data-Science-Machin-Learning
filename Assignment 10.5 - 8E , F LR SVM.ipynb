{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1> <font color='red'>Assignment 10.5</font> : <font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCgMNEvI4Zxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANUNIqCe4Zxn"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, Y_train, y_test = train_test_split(X, y, test_size = 0.2, train_size = 0.8 )\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(x_train, Y_train, test_size = 0.25, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma=0.001, random_state=10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier = SVC(gamma = 0.001, C = 100, random_state = 10)\n",
    "Classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.51740852e+00, -2.40540050e+00, -1.04505580e+00, -4.72460271e-01,\n",
       "       -7.52049835e-01, -1.61537866e-02,  3.33798663e-01,  1.55958703e+00,\n",
       "       -3.33621204e+00,  5.36309552e-02, -3.08571748e+00, -1.69870404e+00,\n",
       "       -3.39248117e+00, -3.17681954e+00,  1.90609663e+00, -3.09235315e+00,\n",
       "       -1.80786614e+00,  2.02475157e+00,  2.82826166e+00, -2.91613111e+00,\n",
       "       -2.56043348e+00, -2.32285894e+00, -2.38533820e+00, -3.17925371e+00,\n",
       "        4.99353323e-01, -1.12841474e+00,  7.14426767e-01, -8.04194665e-02,\n",
       "        1.10350142e+00, -3.33482492e+00, -2.04619462e+00, -2.34965591e+00,\n",
       "       -3.44904087e+00, -2.88499102e+00, -2.64434297e+00, -2.26017108e+00,\n",
       "       -9.91608384e-01,  1.58021983e+00,  1.18673370e+00, -2.45073636e+00,\n",
       "       -3.12699770e+00,  1.49975315e+00,  1.42100233e+00, -4.21927885e+00,\n",
       "        1.01816879e+00,  1.62261938e+00, -2.55636238e+00, -1.22252635e+00,\n",
       "       -8.27087120e-01, -3.32807469e+00, -2.77745179e+00, -2.73099001e-01,\n",
       "        1.29268062e-01, -2.86622227e+00,  1.82973408e+00,  1.05279075e-01,\n",
       "       -3.91831465e+00, -2.06569878e-01,  1.73085960e+00, -8.66264949e-01,\n",
       "       -5.03154321e-01, -3.11694409e+00, -4.27630295e-01, -2.65098950e+00,\n",
       "       -4.77263129e+00, -3.47340170e+00, -2.97008992e+00, -2.90375626e+00,\n",
       "       -3.93529748e+00,  1.38955499e+00,  2.14895437e+00, -3.90633467e+00,\n",
       "       -2.64570342e+00, -3.63664327e+00, -3.49592750e+00, -1.60777530e+00,\n",
       "        2.52021572e+00, -4.49761299e+00, -1.46506311e+00,  1.70987064e+00,\n",
       "       -4.22431334e-01, -1.70486753e+00, -2.15137618e+00,  2.98539124e+00,\n",
       "        2.17000077e+00, -2.46671557e+00,  8.56062214e-01, -1.91073847e-01,\n",
       "       -2.99298540e+00, -6.22104999e-01,  9.97708251e-01, -2.95701502e+00,\n",
       "       -1.43712311e+00, -1.44122424e+00, -1.46936987e+00, -3.41325739e+00,\n",
       "        9.12214353e-01, -3.66579780e+00, -2.00436223e+00, -3.64798827e+00,\n",
       "       -3.20884659e+00, -3.08863868e-01, -2.65586255e+00, -2.57447321e+00,\n",
       "        1.58937466e+00, -3.51992103e+00, -3.50101496e+00, -2.84514241e+00,\n",
       "       -9.82627338e-01,  4.84004419e-01, -4.34738715e+00, -2.90384669e+00,\n",
       "       -2.60754458e+00,  2.53562788e-01, -2.84772987e+00, -1.69400014e+00,\n",
       "       -2.97759509e+00, -1.60894356e+00, -9.18095345e-01, -4.04596278e+00,\n",
       "        3.00140328e+00, -2.40627078e+00, -2.47286420e+00,  3.43483771e-01,\n",
       "       -2.93000557e+00, -2.63366114e+00,  5.43376952e-01,  1.57550066e+00,\n",
       "       -2.94858082e+00,  4.86813519e-01,  1.12985849e+00, -1.00111429e+00,\n",
       "        2.34825359e+00,  1.60799676e+00,  3.02718568e-01,  1.22649715e+00,\n",
       "       -2.39047765e+00,  1.49562879e+00,  1.98444838e+00, -2.04139823e+00,\n",
       "       -5.19073873e+00, -1.86030497e+00,  2.31413732e+00, -1.82713670e+00,\n",
       "       -2.81730747e+00, -3.21747045e+00, -2.15504557e+00, -2.98882953e+00,\n",
       "       -2.74917495e+00, -2.42382376e+00, -1.37156368e+00,  1.61277425e+00,\n",
       "       -2.96905476e+00,  1.72111522e+00, -2.34756507e+00, -1.91014763e+00,\n",
       "       -2.43340822e+00, -7.31731504e-01,  4.69332341e-01, -2.72545444e+00,\n",
       "        1.64044477e+00, -2.37537858e+00,  1.15802725e+00, -2.34059827e+00,\n",
       "       -1.64657923e+00, -1.03932163e+00, -3.25777048e+00,  1.34917533e+00,\n",
       "        1.88848269e+00,  7.46420534e-01, -2.59388840e+00, -2.15502861e+00,\n",
       "       -8.13785673e-01,  9.38651652e-01, -2.84202976e+00, -1.85776791e+00,\n",
       "        1.51170695e+00, -3.83388686e+00, -1.25907169e+00, -1.32827540e+00,\n",
       "       -2.66315238e+00, -4.12851944e+00,  1.75297082e+00, -1.22371695e+00,\n",
       "       -2.12902992e+00, -1.23027227e+00, -2.87632837e+00,  1.38917117e+00,\n",
       "       -2.88289416e+00, -2.30607292e+00, -1.84577318e+00, -1.69791338e+00,\n",
       "       -2.54725713e+00, -1.65878538e+00,  2.78782421e-01, -2.03557587e+00,\n",
       "        1.41280054e+00,  7.81779060e-01,  2.06314673e-02, -2.40473866e+00,\n",
       "        2.08258187e+00, -1.51563031e+00, -3.67279733e+00, -2.05356159e+00,\n",
       "       -2.65262583e+00, -2.31286795e+00, -1.79136606e+00,  6.61008680e-01,\n",
       "       -3.50227124e+00, -2.06471360e+00, -3.58431994e+00, -2.80145043e+00,\n",
       "        4.72117424e-01,  1.38025849e+00, -1.68752343e+00,  1.62125621e+00,\n",
       "        1.33957399e+00, -1.71592960e+00,  1.43458350e+00, -3.09390571e+00,\n",
       "       -3.32791823e+00, -4.76359305e-01, -3.42942569e+00, -2.99303988e+00,\n",
       "        7.04049924e-01,  1.48151220e+00,  2.95328724e+00, -1.68987115e+00,\n",
       "        2.91252409e+00,  1.57033228e+00, -3.54690897e+00, -3.43982605e+00,\n",
       "       -1.81174962e+00, -7.00486111e-01, -3.14794071e+00, -2.47280525e+00,\n",
       "       -2.89715814e+00, -2.00145718e+00, -2.51962630e+00, -1.61839109e+00,\n",
       "       -3.38570077e+00, -3.90218002e+00, -3.08694915e+00, -2.98012679e-01,\n",
       "       -1.08014388e+00, -2.93466006e+00, -2.54234944e+00,  1.53107299e+00,\n",
       "       -1.29742805e+00, -2.80148079e+00, -2.79785856e+00, -3.28366352e+00,\n",
       "       -2.94145411e+00, -2.90856794e+00, -1.96429401e+00, -5.23848568e-01,\n",
       "       -2.33949544e+00,  1.49988438e+00, -3.51124728e+00,  1.05000105e+00,\n",
       "       -3.29047512e+00, -1.61405456e+00,  1.67857014e+00, -3.96873806e+00,\n",
       "        1.78453222e+00, -3.88395722e+00,  1.27430438e+00, -2.13037229e+00,\n",
       "        1.61466535e-01, -3.14334574e+00, -3.63377284e+00, -1.69017323e+00,\n",
       "       -3.51205973e+00, -3.14270639e+00, -4.70646450e+00,  5.02865319e-01,\n",
       "       -1.66323979e+00, -4.09768459e+00,  1.58467411e-01, -2.18991967e+00,\n",
       "       -2.56963272e+00, -2.42634899e+00,  1.35296428e+00, -3.01227710e+00,\n",
       "       -3.03057831e+00, -4.68175033e+00,  1.37337647e+00, -3.72400749e+00,\n",
       "       -1.76590332e+00, -2.25987423e-01,  1.94806844e+00, -2.96506401e+00,\n",
       "       -1.75361047e+00,  2.39930324e-01, -2.28139703e+00, -1.56504503e+00,\n",
       "        1.38267679e-01,  1.29849226e+00, -3.02936225e+00, -6.57268497e-01,\n",
       "       -1.32713433e+00,  1.78266068e+00, -3.12702198e+00, -4.12081483e+00,\n",
       "        2.09870779e+00, -2.30330929e+00,  1.53680177e+00,  8.05234451e-01,\n",
       "       -1.74478639e+00, -3.96335053e+00, -2.34071364e+00, -2.92895822e+00,\n",
       "       -7.30794507e-01, -2.71618862e+00, -3.18984246e+00, -4.01389871e+00,\n",
       "       -3.41140612e+00, -6.56427827e-01,  7.07220468e-01, -2.43209757e+00,\n",
       "        2.04072394e+00, -3.36113443e+00, -1.59737912e+00,  1.17800196e+00,\n",
       "       -2.93036032e+00, -2.99767964e+00, -2.82834786e+00, -3.13677782e+00,\n",
       "       -9.19591790e-01, -2.28579386e+00,  3.75768401e-02, -3.14798758e+00,\n",
       "        1.72028560e+00,  2.25514019e-01,  1.43558654e+00, -2.99937885e+00,\n",
       "       -1.89344338e+00,  1.35521141e+00, -1.40866123e+00,  1.24582985e+00,\n",
       "       -2.30930358e+00,  2.88822091e+00, -1.88398947e+00, -2.63530493e+00,\n",
       "       -5.52495891e+00, -2.59993271e+00,  1.33400557e+00,  1.51295972e+00,\n",
       "       -2.38746302e+00, -1.79754080e+00, -3.70756225e+00, -2.10742405e+00,\n",
       "       -1.07607459e+00,  1.54656172e+00, -3.08486865e+00, -3.21066384e+00,\n",
       "       -2.06301751e+00, -3.80126426e-01, -1.83047145e+00, -3.57896513e+00,\n",
       "       -3.05347830e+00,  1.72266227e+00, -1.51541984e+00, -3.49603145e+00,\n",
       "       -2.78378934e+00, -2.44370536e+00, -2.53497873e+00, -3.84858571e+00,\n",
       "       -1.88707897e+00,  1.03032881e+00,  1.73196047e+00, -3.52601782e+00,\n",
       "       -5.46176082e+00, -9.60871848e-01, -2.97166640e+00, -1.33222697e+00,\n",
       "        1.20494106e+00,  1.66549197e+00,  5.96432076e-02, -1.80208886e+00,\n",
       "       -6.83461658e-02,  1.86694486e+00, -2.95098269e+00,  2.25090532e+00,\n",
       "        1.44141909e+00,  1.72451463e+00, -2.83464268e+00, -2.34500746e+00,\n",
       "       -3.06467820e+00, -1.86313065e+00, -2.28159216e+00, -3.02018000e+00,\n",
       "       -3.39572202e+00,  1.07177071e+00,  2.41322348e+00, -2.00429506e+00,\n",
       "       -3.77226521e+00, -2.30206431e+00, -2.48066754e+00, -3.05781029e+00,\n",
       "       -2.30147210e+00, -2.51366673e+00, -3.46228840e+00, -1.13872730e+00,\n",
       "       -1.76196180e+00, -5.26783422e+00, -1.48054383e+00, -2.16869525e+00,\n",
       "       -4.85559368e+00, -3.19658406e+00,  1.85751275e+00,  1.04243780e+00,\n",
       "       -2.78543880e+00, -1.41672019e+00, -2.82250725e-01,  1.54357391e+00,\n",
       "        6.16947668e-01, -2.95446375e+00,  2.02856441e+00, -3.02830100e+00,\n",
       "       -2.62624029e+00, -3.40409257e+00,  1.10383184e+00, -6.70761549e-01,\n",
       "       -3.68541027e+00,  7.34125603e-01, -2.76201114e+00, -3.91063640e+00,\n",
       "       -2.46651732e+00,  3.24167995e+00, -1.59665838e+00, -3.74903130e-01,\n",
       "       -3.79491391e+00, -2.28037929e+00, -2.97639096e+00,  1.27040665e-03,\n",
       "       -3.10002536e+00, -3.09961289e+00,  1.00083016e+00,  5.85080600e-01,\n",
       "       -1.46340823e+00, -2.19539875e+00, -2.09137223e+00, -2.63453434e+00,\n",
       "       -3.26926958e+00, -3.25146958e+00,  1.29843382e+00, -1.62965187e+00,\n",
       "       -1.51856563e+00, -3.16644083e+00, -3.67902735e+00, -3.44245690e+00,\n",
       "       -2.45194780e-01, -6.22356276e-01,  1.73584716e+00,  4.17161634e-01,\n",
       "        1.35910095e+00, -2.14611039e+00, -3.56508757e+00, -4.59723356e-01,\n",
       "       -3.54944387e+00, -3.63871147e+00, -2.20154889e+00, -2.21634335e+00,\n",
       "       -1.30702112e+00, -2.86422077e+00, -4.08984962e+00,  1.84021332e+00,\n",
       "       -8.53737092e-01, -4.18006118e-01, -2.24804420e+00, -2.86444515e+00,\n",
       "       -2.85544706e+00, -2.75402724e+00, -2.60611586e+00, -3.23739604e+00,\n",
       "       -2.42103172e+00,  1.35083719e+00, -2.05748311e+00, -2.76416251e+00,\n",
       "       -2.56487514e+00, -2.66306621e+00,  5.69667576e-01, -2.59126002e+00,\n",
       "       -2.29272859e+00,  1.84058774e+00,  1.16087189e+00,  2.21750155e+00,\n",
       "        2.81245212e+00,  1.44357838e+00, -3.30433183e+00,  1.03073311e+00,\n",
       "       -3.74030009e+00,  7.55684656e-01,  1.37559363e+00, -1.30228440e+00,\n",
       "        2.48247693e+00, -1.46147590e+00, -4.17553903e+00, -4.87514579e-01,\n",
       "       -3.10543574e+00, -3.53206261e+00, -3.97604509e+00, -3.05863097e+00,\n",
       "       -1.64049932e+00, -2.30522055e-01, -4.04322546e+00, -2.45566781e+00,\n",
       "        8.09421847e-01, -3.45495674e+00, -3.41869550e+00, -1.86454931e+00,\n",
       "       -2.49314904e+00, -2.95864589e+00, -4.47457334e-01, -2.20561025e+00,\n",
       "       -2.35369191e+00, -1.79431577e+00, -1.30343385e+00,  5.41737326e-01,\n",
       "        1.78575999e+00, -2.32693010e+00,  4.42443346e-01, -2.93552841e+00,\n",
       "       -2.16121412e+00, -3.06488749e+00, -4.40440700e+00, -3.65790443e+00,\n",
       "        5.08300353e-01, -2.66952295e+00,  1.29442397e+00,  1.28015793e+00,\n",
       "       -3.26283883e+00,  1.59041542e+00, -2.46606932e+00, -3.75905143e+00,\n",
       "        1.50907539e+00, -2.85413995e+00,  1.57068771e+00, -3.56689987e+00,\n",
       "       -5.35207842e-01, -3.22984061e+00, -1.87868636e+00,  3.10169440e+00,\n",
       "       -3.46132035e+00, -3.42984823e+00,  3.34862376e-01, -2.94045054e+00,\n",
       "       -8.44577635e-01, -3.27414077e+00, -2.42066057e+00,  1.13946617e+00,\n",
       "       -1.46591034e+00, -3.38597497e+00, -3.32280477e+00,  1.78057084e+00,\n",
       "       -3.65707787e+00, -2.46210971e+00, -2.56374566e+00,  2.23945917e-01,\n",
       "       -7.20309675e-01, -3.45520652e+00, -1.29288440e+00, -1.50414842e+00,\n",
       "       -2.16924588e+00,  1.63107098e+00,  1.04013105e+00, -2.25307752e+00,\n",
       "       -3.31911152e+00, -2.33035148e+00,  1.29175738e+00, -7.35228546e-01,\n",
       "       -3.07452556e+00, -1.64231962e+00,  9.65703918e-01, -3.28818746e+00,\n",
       "       -3.39629112e+00, -4.40931536e+00, -5.84119416e-02, -2.93851906e+00,\n",
       "       -2.76692189e+00, -5.72959763e-01,  4.22757478e+00, -3.79851372e+00,\n",
       "       -1.15042291e+00, -1.69334071e+00,  1.39651050e+00, -2.87539980e+00,\n",
       "       -3.89137595e+00, -3.40919499e+00, -2.55876909e+00,  1.65033598e+00,\n",
       "       -6.91930451e-01,  1.64494789e+00, -1.77660553e+00, -1.18577481e+00,\n",
       "        1.57977574e+00, -2.88608410e+00, -3.91819897e-01, -6.43972581e-01,\n",
       "        1.59536646e+00, -2.45256667e+00, -2.82533846e+00, -8.85607181e-01,\n",
       "        2.11287739e+00,  9.57077635e-03, -3.80139560e+00,  9.37896116e-01,\n",
       "       -3.69591230e+00, -3.43658185e+00,  1.71352877e+00, -5.01423336e+00,\n",
       "       -1.91406712e+00,  1.58298374e+00, -3.85999241e+00, -1.64728252e+00,\n",
       "       -3.80036604e+00, -1.91345915e+00,  7.46229497e-01, -1.26292432e+00,\n",
       "       -5.13940362e-01, -2.47048028e+00,  9.05562382e-01, -3.17011296e+00,\n",
       "       -2.37234074e+00,  1.71751175e+00, -2.02364814e+00, -1.79422450e+00,\n",
       "       -2.51110535e+00, -3.09579103e+00, -2.20609131e+00, -4.15533292e+00,\n",
       "       -3.20894975e+00, -2.30088547e+00,  1.50064965e+00,  9.90448103e-01,\n",
       "       -3.21790995e+00,  1.66271885e+00, -1.72371897e+00,  3.05251421e+00,\n",
       "       -1.18142058e+00, -1.55288825e+00,  2.12685309e+00,  1.19717067e+00,\n",
       "       -2.89824993e+00,  1.54589674e+00, -9.72012213e-01, -2.06921327e+00,\n",
       "        1.87296257e+00, -8.44566081e-01, -2.89862328e+00,  3.28314499e-01,\n",
       "       -8.63244098e-02, -1.77747438e+00, -2.70029131e+00, -2.88532649e-01,\n",
       "       -2.51323373e+00, -6.00561512e-01,  1.31343734e+00, -2.02378736e+00,\n",
       "       -7.77550396e-01, -3.77719746e+00, -2.77442461e+00, -3.80329855e-01,\n",
       "        8.13174313e-01, -9.09366738e-01, -4.45963290e+00,  1.44139657e+00,\n",
       "       -1.28697102e+00,  8.65175924e-01, -1.07135356e+00, -1.03859451e+00,\n",
       "        3.86863810e+00, -2.93374789e+00,  1.48856591e+00, -3.42189164e-01,\n",
       "       -2.30738101e+00, -3.50600534e+00,  4.86316534e-01, -3.28511183e+00,\n",
       "       -3.27652481e+00,  1.80223166e+00, -2.00710231e+00,  1.10942021e+00,\n",
       "        1.70905199e+00, -1.77540268e-01, -2.87401328e+00,  6.68666691e-01,\n",
       "       -2.53306408e+00, -2.88073371e+00, -1.45563861e+00, -2.07629532e+00,\n",
       "       -1.10685887e+00, -3.30746297e+00, -1.70979613e+00,  1.58996274e+00,\n",
       "       -3.52504166e+00, -1.52132704e+00, -1.64646238e+00, -2.48355981e+00,\n",
       "       -1.94542204e+00, -3.83035737e+00,  4.05074905e-01,  1.56887722e+00,\n",
       "       -2.15610384e+00, -3.99607552e+00, -2.33422436e+00, -2.29303782e+00,\n",
       "       -1.54683690e+00, -5.81657121e-01, -2.49388453e+00, -4.46141217e+00,\n",
       "       -2.06159009e+00, -2.37134020e+00, -1.27964995e+00,  2.15268691e+00,\n",
       "       -2.40692701e+00, -3.62409264e+00,  2.26935745e-01, -2.94748477e+00,\n",
       "       -2.69686332e+00, -1.73979814e+00, -3.23192990e+00, -2.28384442e+00,\n",
       "       -2.75296230e+00,  9.46333163e-01, -1.37997218e+00,  7.33829245e-01,\n",
       "        2.36686760e+00, -2.11250101e+00, -1.16846517e+00, -6.85569958e-01,\n",
       "       -1.69766301e+00, -5.58035918e-02, -2.49515108e+00,  4.74839117e-01,\n",
       "       -2.55450898e+00,  1.62323717e+00,  2.16178683e+00, -5.55905779e-01,\n",
       "       -2.17375021e+00,  8.71717022e-01, -6.22630835e-01,  8.67750154e-02,\n",
       "       -2.35013094e+00, -2.86427518e+00, -1.91281750e+00, -2.99443434e+00,\n",
       "       -1.35208685e+00,  2.13145195e+00, -3.08693872e+00, -2.36854157e+00,\n",
       "        1.74678118e+00, -1.79003733e+00, -3.14734680e+00, -3.13537596e+00,\n",
       "       -2.64063999e+00, -2.01534615e+00, -1.61546711e+00, -3.00235003e+00,\n",
       "        3.14245338e+00, -1.67267914e+00,  1.36336289e+00, -2.87844247e+00,\n",
       "       -1.80499842e+00, -1.93414556e+00, -3.53400908e+00, -4.04738960e+00,\n",
       "       -2.30279272e+00,  2.20236618e+00,  7.73784189e-01,  1.36597646e+00,\n",
       "       -2.72847741e+00, -2.54361795e+00, -3.57504502e+00, -2.06341078e+00,\n",
       "       -1.78656807e+00,  7.91114382e-01, -4.24927468e-01, -1.93077940e+00,\n",
       "       -2.56432108e+00, -1.51574705e+00, -2.74750339e+00, -2.50630370e+00,\n",
       "        1.42697572e+00, -2.85912160e+00, -2.86778818e+00, -1.21798547e+00,\n",
       "       -3.80963697e+00, -2.26750407e+00,  1.68138236e+00, -4.21487794e+00,\n",
       "       -2.26607687e+00,  1.46444881e+00, -1.72562590e+00,  9.76504046e-02,\n",
       "        8.51520911e-01,  2.27205104e+00, -1.90408702e+00,  1.58530933e+00,\n",
       "       -2.05286944e+00, -4.26508603e+00,  1.17784092e-01, -2.29827209e+00,\n",
       "       -5.39000303e+00,  1.15222873e+00,  1.89903163e+00, -2.81644557e+00,\n",
       "        2.37698207e-01,  1.06729949e+00,  2.54412097e-01, -2.67526404e-01,\n",
       "        2.16789641e+00, -1.16808575e+00, -2.19909056e+00,  1.03883489e+00,\n",
       "       -3.15335276e+00, -2.43570319e+00,  2.03184896e+00, -6.83467155e-02,\n",
       "       -3.17443827e+00,  1.79046503e+00, -4.16898038e+00, -2.93527907e+00,\n",
       "        2.99339062e-01, -2.74490917e+00,  1.52270759e+00,  2.15996351e+00,\n",
       "       -1.38933914e+00, -9.63997547e-02,  2.04471446e+00, -3.32972442e+00,\n",
       "        1.70954476e+00, -3.25643323e+00, -2.59941263e+00, -4.14787130e-01,\n",
       "       -1.70980354e+00, -2.22892691e+00,  8.86836387e-01,  1.71865696e+00,\n",
       "        8.16300059e-02, -2.96299106e+00, -3.21680851e+00, -2.91568534e+00,\n",
       "        1.45535555e+00, -1.96612736e+00,  1.42311663e+00, -2.62634174e+00,\n",
       "        7.44616938e-01, -2.83403330e+00,  2.91990419e+00, -1.29044499e+00,\n",
       "       -2.54019854e+00, -2.72942279e+00, -1.35707907e+00,  1.91154486e+00,\n",
       "        2.37620632e+00,  1.06302212e+00, -6.82944455e-02, -3.25236828e+00,\n",
       "       -2.42357847e+00,  1.67404329e+00, -2.82634137e+00, -2.70889929e+00,\n",
       "        2.73550663e+00, -7.09430187e-01,  9.98516962e-01, -6.22179770e-01,\n",
       "        2.00598044e+00, -1.06071952e+00, -1.31310637e+00, -1.99601854e+00,\n",
       "        1.70748228e+00, -7.45405231e-01, -1.84335812e-01, -3.54054570e+00,\n",
       "       -1.81335037e+00, -2.45283620e+00,  2.19899483e+00,  1.99635429e+00,\n",
       "       -4.05954149e+00, -1.93205024e+00, -1.70891353e+00,  1.83497663e+00,\n",
       "       -9.14062530e-01, -2.56535487e+00,  6.81711719e-01, -1.81460248e+00,\n",
       "        1.17379511e+00,  1.56854845e+00, -1.09992622e+00, -1.09482506e+00,\n",
       "        1.79565630e+00, -3.01232812e+00, -1.40797014e-01, -1.91383098e+00,\n",
       "       -4.15242262e+00, -3.16242743e+00, -2.66802719e+00,  1.53498944e+00,\n",
       "       -2.43287842e+00, -2.69311993e+00, -2.93671242e+00, -9.52780437e-01,\n",
       "       -2.38878098e+00, -3.74732367e+00,  4.91574091e-01, -2.31159267e+00,\n",
       "       -2.59254351e+00, -2.27549226e+00, -1.57960657e+00, -3.79040686e+00,\n",
       "       -2.20140495e+00, -6.30848599e-01, -4.69850784e+00, -3.72887976e+00,\n",
       "        2.65747952e+00,  1.49583644e+00, -2.95205252e+00, -2.13291347e+00,\n",
       "        3.49546717e-01, -2.76016766e+00, -2.06236664e+00, -1.88222004e+00,\n",
       "       -2.33477831e+00, -3.13558323e+00, -1.43866572e+00,  2.24072197e-01,\n",
       "       -3.55329036e+00,  1.51131976e+00, -1.42040622e+00,  2.22701251e+00,\n",
       "        2.66865058e-02, -5.86152901e-01, -2.92555321e+00, -5.41080020e-01,\n",
       "       -2.90889928e+00, -2.42515659e+00,  2.46148354e+00, -3.13229716e+00,\n",
       "       -2.92023928e+00,  1.62304174e+00, -7.68234155e-01, -1.66862117e+00,\n",
       "        1.60282009e+00, -3.97915424e+00, -1.92112206e+00, -1.14113185e+00,\n",
       "       -2.28762719e+00, -2.27209412e+00, -2.54828997e+00, -6.27979826e-01,\n",
       "        2.87865259e+00, -2.60654887e+00, -1.94396097e+00, -3.57495374e+00,\n",
       "       -2.17888806e+00, -3.34389120e+00,  6.55419326e-01,  2.34354861e+00,\n",
       "       -6.71022595e-02, -3.38912340e+00, -1.45835285e-01, -1.96515241e+00,\n",
       "       -2.87032025e-01, -2.11271188e+00, -3.08527675e+00, -3.01382100e+00,\n",
       "       -2.90696501e+00,  2.45823166e-01, -3.74413688e+00,  1.60015298e+00,\n",
       "        1.42097518e+00, -2.00813906e+00, -3.09623645e+00, -3.64586052e+00,\n",
       "        1.54669669e+00, -2.08411375e-01,  2.00022868e+00, -1.64720069e+00,\n",
       "       -1.24598832e+00, -8.42935541e-01, -1.95976236e+00, -2.94508785e+00,\n",
       "       -1.12512465e+00,  1.91046418e+00,  3.42550158e-01,  1.25402257e+00,\n",
       "        1.38422014e+00, -2.84390800e+00, -3.46385088e+00, -9.74439836e-01,\n",
       "       -3.03489417e+00, -2.86139933e+00, -2.33909088e+00, -2.56128365e+00,\n",
       "       -2.78309706e+00,  5.99906221e-01, -4.10317783e-01, -1.76686184e+00])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.decision_function(X_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h43kDT3M41u5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.51740852e+00, -2.40540050e+00, -1.04505580e+00, -4.72460271e-01,\n",
       "       -7.52049835e-01, -1.61537866e-02,  3.33798663e-01,  1.55958703e+00,\n",
       "       -3.33621204e+00,  5.36309552e-02, -3.08571748e+00, -1.69870404e+00,\n",
       "       -3.39248117e+00, -3.17681954e+00,  1.90609663e+00, -3.09235315e+00,\n",
       "       -1.80786614e+00,  2.02475157e+00,  2.82826166e+00, -2.91613111e+00,\n",
       "       -2.56043348e+00, -2.32285894e+00, -2.38533820e+00, -3.17925371e+00,\n",
       "        4.99353323e-01, -1.12841474e+00,  7.14426767e-01, -8.04194665e-02,\n",
       "        1.10350142e+00, -3.33482492e+00, -2.04619462e+00, -2.34965591e+00,\n",
       "       -3.44904087e+00, -2.88499102e+00, -2.64434297e+00, -2.26017108e+00,\n",
       "       -9.91608384e-01,  1.58021983e+00,  1.18673370e+00, -2.45073636e+00,\n",
       "       -3.12699770e+00,  1.49975315e+00,  1.42100233e+00, -4.21927885e+00,\n",
       "        1.01816879e+00,  1.62261938e+00, -2.55636238e+00, -1.22252635e+00,\n",
       "       -8.27087120e-01, -3.32807469e+00, -2.77745179e+00, -2.73099001e-01,\n",
       "        1.29268062e-01, -2.86622227e+00,  1.82973408e+00,  1.05279075e-01,\n",
       "       -3.91831465e+00, -2.06569878e-01,  1.73085960e+00, -8.66264949e-01,\n",
       "       -5.03154321e-01, -3.11694409e+00, -4.27630295e-01, -2.65098950e+00,\n",
       "       -4.77263129e+00, -3.47340170e+00, -2.97008992e+00, -2.90375626e+00,\n",
       "       -3.93529748e+00,  1.38955499e+00,  2.14895437e+00, -3.90633467e+00,\n",
       "       -2.64570342e+00, -3.63664327e+00, -3.49592750e+00, -1.60777530e+00,\n",
       "        2.52021572e+00, -4.49761299e+00, -1.46506311e+00,  1.70987064e+00,\n",
       "       -4.22431334e-01, -1.70486753e+00, -2.15137618e+00,  2.98539124e+00,\n",
       "        2.17000077e+00, -2.46671557e+00,  8.56062214e-01, -1.91073847e-01,\n",
       "       -2.99298540e+00, -6.22104999e-01,  9.97708251e-01, -2.95701502e+00,\n",
       "       -1.43712311e+00, -1.44122424e+00, -1.46936987e+00, -3.41325739e+00,\n",
       "        9.12214353e-01, -3.66579780e+00, -2.00436223e+00, -3.64798827e+00,\n",
       "       -3.20884659e+00, -3.08863868e-01, -2.65586255e+00, -2.57447321e+00,\n",
       "        1.58937466e+00, -3.51992103e+00, -3.50101496e+00, -2.84514241e+00,\n",
       "       -9.82627338e-01,  4.84004420e-01, -4.34738715e+00, -2.90384669e+00,\n",
       "       -2.60754458e+00,  2.53562788e-01, -2.84772987e+00, -1.69400014e+00,\n",
       "       -2.97759509e+00, -1.60894356e+00, -9.18095345e-01, -4.04596278e+00,\n",
       "        3.00140328e+00, -2.40627078e+00, -2.47286420e+00,  3.43483771e-01,\n",
       "       -2.93000557e+00, -2.63366114e+00,  5.43376952e-01,  1.57550066e+00,\n",
       "       -2.94858082e+00,  4.86813519e-01,  1.12985849e+00, -1.00111429e+00,\n",
       "        2.34825359e+00,  1.60799676e+00,  3.02718568e-01,  1.22649715e+00,\n",
       "       -2.39047765e+00,  1.49562879e+00,  1.98444838e+00, -2.04139823e+00,\n",
       "       -5.19073873e+00, -1.86030497e+00,  2.31413732e+00, -1.82713670e+00,\n",
       "       -2.81730747e+00, -3.21747045e+00, -2.15504557e+00, -2.98882953e+00,\n",
       "       -2.74917495e+00, -2.42382376e+00, -1.37156368e+00,  1.61277425e+00,\n",
       "       -2.96905476e+00,  1.72111522e+00, -2.34756507e+00, -1.91014763e+00,\n",
       "       -2.43340822e+00, -7.31731504e-01,  4.69332341e-01, -2.72545444e+00,\n",
       "        1.64044477e+00, -2.37537858e+00,  1.15802725e+00, -2.34059827e+00,\n",
       "       -1.64657923e+00, -1.03932163e+00, -3.25777048e+00,  1.34917533e+00,\n",
       "        1.88848269e+00,  7.46420534e-01, -2.59388840e+00, -2.15502861e+00,\n",
       "       -8.13785673e-01,  9.38651652e-01, -2.84202976e+00, -1.85776791e+00,\n",
       "        1.51170695e+00, -3.83388686e+00, -1.25907169e+00, -1.32827540e+00,\n",
       "       -2.66315238e+00, -4.12851944e+00,  1.75297082e+00, -1.22371695e+00,\n",
       "       -2.12902992e+00, -1.23027227e+00, -2.87632837e+00,  1.38917117e+00,\n",
       "       -2.88289416e+00, -2.30607292e+00, -1.84577318e+00, -1.69791338e+00,\n",
       "       -2.54725713e+00, -1.65878538e+00,  2.78782421e-01, -2.03557587e+00,\n",
       "        1.41280054e+00,  7.81779060e-01,  2.06314673e-02, -2.40473866e+00,\n",
       "        2.08258187e+00, -1.51563031e+00, -3.67279733e+00, -2.05356159e+00,\n",
       "       -2.65262583e+00, -2.31286795e+00, -1.79136606e+00,  6.61008680e-01,\n",
       "       -3.50227124e+00, -2.06471360e+00, -3.58431994e+00, -2.80145043e+00,\n",
       "        4.72117424e-01,  1.38025849e+00, -1.68752343e+00,  1.62125621e+00,\n",
       "        1.33957399e+00, -1.71592960e+00,  1.43458350e+00, -3.09390571e+00,\n",
       "       -3.32791823e+00, -4.76359305e-01, -3.42942569e+00, -2.99303988e+00,\n",
       "        7.04049924e-01,  1.48151220e+00,  2.95328724e+00, -1.68987115e+00,\n",
       "        2.91252409e+00,  1.57033228e+00, -3.54690897e+00, -3.43982605e+00,\n",
       "       -1.81174962e+00, -7.00486111e-01, -3.14794071e+00, -2.47280525e+00,\n",
       "       -2.89715814e+00, -2.00145718e+00, -2.51962630e+00, -1.61839109e+00,\n",
       "       -3.38570077e+00, -3.90218002e+00, -3.08694915e+00, -2.98012679e-01,\n",
       "       -1.08014388e+00, -2.93466006e+00, -2.54234944e+00,  1.53107299e+00,\n",
       "       -1.29742805e+00, -2.80148079e+00, -2.79785856e+00, -3.28366352e+00,\n",
       "       -2.94145411e+00, -2.90856794e+00, -1.96429401e+00, -5.23848568e-01,\n",
       "       -2.33949544e+00,  1.49988438e+00, -3.51124728e+00,  1.05000105e+00,\n",
       "       -3.29047512e+00, -1.61405456e+00,  1.67857014e+00, -3.96873806e+00,\n",
       "        1.78453222e+00, -3.88395722e+00,  1.27430438e+00, -2.13037229e+00,\n",
       "        1.61466535e-01, -3.14334574e+00, -3.63377284e+00, -1.69017323e+00,\n",
       "       -3.51205973e+00, -3.14270639e+00, -4.70646450e+00,  5.02865319e-01,\n",
       "       -1.66323979e+00, -4.09768459e+00,  1.58467411e-01, -2.18991967e+00,\n",
       "       -2.56963272e+00, -2.42634899e+00,  1.35296428e+00, -3.01227710e+00,\n",
       "       -3.03057831e+00, -4.68175033e+00,  1.37337647e+00, -3.72400749e+00,\n",
       "       -1.76590332e+00, -2.25987423e-01,  1.94806844e+00, -2.96506401e+00,\n",
       "       -1.75361047e+00,  2.39930324e-01, -2.28139703e+00, -1.56504503e+00,\n",
       "        1.38267679e-01,  1.29849226e+00, -3.02936225e+00, -6.57268497e-01,\n",
       "       -1.32713433e+00,  1.78266068e+00, -3.12702198e+00, -4.12081483e+00,\n",
       "        2.09870779e+00, -2.30330929e+00,  1.53680177e+00,  8.05234451e-01,\n",
       "       -1.74478639e+00, -3.96335053e+00, -2.34071364e+00, -2.92895822e+00,\n",
       "       -7.30794507e-01, -2.71618862e+00, -3.18984246e+00, -4.01389871e+00,\n",
       "       -3.41140612e+00, -6.56427827e-01,  7.07220468e-01, -2.43209757e+00,\n",
       "        2.04072394e+00, -3.36113443e+00, -1.59737912e+00,  1.17800196e+00,\n",
       "       -2.93036032e+00, -2.99767964e+00, -2.82834786e+00, -3.13677782e+00,\n",
       "       -9.19591790e-01, -2.28579386e+00,  3.75768401e-02, -3.14798758e+00,\n",
       "        1.72028560e+00,  2.25514019e-01,  1.43558654e+00, -2.99937885e+00,\n",
       "       -1.89344338e+00,  1.35521141e+00, -1.40866123e+00,  1.24582985e+00,\n",
       "       -2.30930358e+00,  2.88822091e+00, -1.88398947e+00, -2.63530493e+00,\n",
       "       -5.52495891e+00, -2.59993271e+00,  1.33400557e+00,  1.51295972e+00,\n",
       "       -2.38746302e+00, -1.79754080e+00, -3.70756225e+00, -2.10742405e+00,\n",
       "       -1.07607459e+00,  1.54656172e+00, -3.08486865e+00, -3.21066384e+00,\n",
       "       -2.06301751e+00, -3.80126426e-01, -1.83047145e+00, -3.57896513e+00,\n",
       "       -3.05347830e+00,  1.72266227e+00, -1.51541984e+00, -3.49603145e+00,\n",
       "       -2.78378934e+00, -2.44370536e+00, -2.53497873e+00, -3.84858571e+00,\n",
       "       -1.88707897e+00,  1.03032881e+00,  1.73196047e+00, -3.52601782e+00,\n",
       "       -5.46176082e+00, -9.60871848e-01, -2.97166640e+00, -1.33222697e+00,\n",
       "        1.20494106e+00,  1.66549197e+00,  5.96432076e-02, -1.80208886e+00,\n",
       "       -6.83461658e-02,  1.86694486e+00, -2.95098269e+00,  2.25090532e+00,\n",
       "        1.44141909e+00,  1.72451463e+00, -2.83464268e+00, -2.34500746e+00,\n",
       "       -3.06467820e+00, -1.86313065e+00, -2.28159216e+00, -3.02018000e+00,\n",
       "       -3.39572202e+00,  1.07177071e+00,  2.41322348e+00, -2.00429506e+00,\n",
       "       -3.77226521e+00, -2.30206431e+00, -2.48066754e+00, -3.05781029e+00,\n",
       "       -2.30147210e+00, -2.51366673e+00, -3.46228840e+00, -1.13872730e+00,\n",
       "       -1.76196180e+00, -5.26783422e+00, -1.48054383e+00, -2.16869525e+00,\n",
       "       -4.85559368e+00, -3.19658406e+00,  1.85751275e+00,  1.04243780e+00,\n",
       "       -2.78543880e+00, -1.41672019e+00, -2.82250725e-01,  1.54357391e+00,\n",
       "        6.16947668e-01, -2.95446375e+00,  2.02856441e+00, -3.02830100e+00,\n",
       "       -2.62624029e+00, -3.40409257e+00,  1.10383184e+00, -6.70761549e-01,\n",
       "       -3.68541027e+00,  7.34125603e-01, -2.76201114e+00, -3.91063640e+00,\n",
       "       -2.46651732e+00,  3.24167995e+00, -1.59665838e+00, -3.74903130e-01,\n",
       "       -3.79491391e+00, -2.28037929e+00, -2.97639096e+00,  1.27040665e-03,\n",
       "       -3.10002536e+00, -3.09961289e+00,  1.00083016e+00,  5.85080600e-01,\n",
       "       -1.46340823e+00, -2.19539875e+00, -2.09137223e+00, -2.63453434e+00,\n",
       "       -3.26926958e+00, -3.25146958e+00,  1.29843382e+00, -1.62965187e+00,\n",
       "       -1.51856563e+00, -3.16644083e+00, -3.67902735e+00, -3.44245690e+00,\n",
       "       -2.45194780e-01, -6.22356276e-01,  1.73584716e+00,  4.17161634e-01,\n",
       "        1.35910095e+00, -2.14611039e+00, -3.56508757e+00, -4.59723356e-01,\n",
       "       -3.54944387e+00, -3.63871147e+00, -2.20154889e+00, -2.21634335e+00,\n",
       "       -1.30702112e+00, -2.86422077e+00, -4.08984962e+00,  1.84021332e+00,\n",
       "       -8.53737092e-01, -4.18006118e-01, -2.24804420e+00, -2.86444515e+00,\n",
       "       -2.85544706e+00, -2.75402724e+00, -2.60611586e+00, -3.23739604e+00,\n",
       "       -2.42103172e+00,  1.35083719e+00, -2.05748311e+00, -2.76416251e+00,\n",
       "       -2.56487514e+00, -2.66306621e+00,  5.69667576e-01, -2.59126002e+00,\n",
       "       -2.29272859e+00,  1.84058774e+00,  1.16087189e+00,  2.21750155e+00,\n",
       "        2.81245212e+00,  1.44357838e+00, -3.30433183e+00,  1.03073311e+00,\n",
       "       -3.74030009e+00,  7.55684656e-01,  1.37559363e+00, -1.30228440e+00,\n",
       "        2.48247693e+00, -1.46147590e+00, -4.17553903e+00, -4.87514579e-01,\n",
       "       -3.10543574e+00, -3.53206261e+00, -3.97604509e+00, -3.05863097e+00,\n",
       "       -1.64049932e+00, -2.30522055e-01, -4.04322546e+00, -2.45566781e+00,\n",
       "        8.09421847e-01, -3.45495674e+00, -3.41869550e+00, -1.86454931e+00,\n",
       "       -2.49314904e+00, -2.95864589e+00, -4.47457334e-01, -2.20561025e+00,\n",
       "       -2.35369191e+00, -1.79431577e+00, -1.30343385e+00,  5.41737326e-01,\n",
       "        1.78575999e+00, -2.32693010e+00,  4.42443346e-01, -2.93552841e+00,\n",
       "       -2.16121412e+00, -3.06488749e+00, -4.40440700e+00, -3.65790443e+00,\n",
       "        5.08300353e-01, -2.66952295e+00,  1.29442397e+00,  1.28015793e+00,\n",
       "       -3.26283883e+00,  1.59041542e+00, -2.46606932e+00, -3.75905143e+00,\n",
       "        1.50907539e+00, -2.85413995e+00,  1.57068771e+00, -3.56689987e+00,\n",
       "       -5.35207842e-01, -3.22984061e+00, -1.87868636e+00,  3.10169440e+00,\n",
       "       -3.46132035e+00, -3.42984823e+00,  3.34862376e-01, -2.94045054e+00,\n",
       "       -8.44577635e-01, -3.27414077e+00, -2.42066057e+00,  1.13946617e+00,\n",
       "       -1.46591034e+00, -3.38597497e+00, -3.32280477e+00,  1.78057084e+00,\n",
       "       -3.65707787e+00, -2.46210971e+00, -2.56374566e+00,  2.23945917e-01,\n",
       "       -7.20309675e-01, -3.45520652e+00, -1.29288440e+00, -1.50414842e+00,\n",
       "       -2.16924588e+00,  1.63107098e+00,  1.04013105e+00, -2.25307752e+00,\n",
       "       -3.31911152e+00, -2.33035148e+00,  1.29175738e+00, -7.35228546e-01,\n",
       "       -3.07452556e+00, -1.64231962e+00,  9.65703918e-01, -3.28818746e+00,\n",
       "       -3.39629112e+00, -4.40931536e+00, -5.84119416e-02, -2.93851906e+00,\n",
       "       -2.76692189e+00, -5.72959763e-01,  4.22757478e+00, -3.79851372e+00,\n",
       "       -1.15042291e+00, -1.69334071e+00,  1.39651050e+00, -2.87539980e+00,\n",
       "       -3.89137595e+00, -3.40919499e+00, -2.55876909e+00,  1.65033598e+00,\n",
       "       -6.91930451e-01,  1.64494789e+00, -1.77660553e+00, -1.18577481e+00,\n",
       "        1.57977574e+00, -2.88608410e+00, -3.91819897e-01, -6.43972581e-01,\n",
       "        1.59536646e+00, -2.45256667e+00, -2.82533846e+00, -8.85607181e-01,\n",
       "        2.11287739e+00,  9.57077634e-03, -3.80139560e+00,  9.37896116e-01,\n",
       "       -3.69591230e+00, -3.43658185e+00,  1.71352877e+00, -5.01423336e+00,\n",
       "       -1.91406712e+00,  1.58298374e+00, -3.85999241e+00, -1.64728252e+00,\n",
       "       -3.80036604e+00, -1.91345915e+00,  7.46229497e-01, -1.26292432e+00,\n",
       "       -5.13940362e-01, -2.47048028e+00,  9.05562382e-01, -3.17011296e+00,\n",
       "       -2.37234074e+00,  1.71751175e+00, -2.02364814e+00, -1.79422450e+00,\n",
       "       -2.51110535e+00, -3.09579103e+00, -2.20609131e+00, -4.15533292e+00,\n",
       "       -3.20894975e+00, -2.30088547e+00,  1.50064965e+00,  9.90448103e-01,\n",
       "       -3.21790995e+00,  1.66271885e+00, -1.72371897e+00,  3.05251421e+00,\n",
       "       -1.18142058e+00, -1.55288825e+00,  2.12685309e+00,  1.19717067e+00,\n",
       "       -2.89824993e+00,  1.54589674e+00, -9.72012213e-01, -2.06921327e+00,\n",
       "        1.87296257e+00, -8.44566081e-01, -2.89862328e+00,  3.28314499e-01,\n",
       "       -8.63244098e-02, -1.77747438e+00, -2.70029131e+00, -2.88532649e-01,\n",
       "       -2.51323373e+00, -6.00561512e-01,  1.31343734e+00, -2.02378736e+00,\n",
       "       -7.77550396e-01, -3.77719746e+00, -2.77442461e+00, -3.80329855e-01,\n",
       "        8.13174313e-01, -9.09366738e-01, -4.45963290e+00,  1.44139657e+00,\n",
       "       -1.28697102e+00,  8.65175924e-01, -1.07135356e+00, -1.03859451e+00,\n",
       "        3.86863810e+00, -2.93374789e+00,  1.48856591e+00, -3.42189164e-01,\n",
       "       -2.30738101e+00, -3.50600534e+00,  4.86316534e-01, -3.28511183e+00,\n",
       "       -3.27652481e+00,  1.80223166e+00, -2.00710231e+00,  1.10942021e+00,\n",
       "        1.70905199e+00, -1.77540268e-01, -2.87401328e+00,  6.68666691e-01,\n",
       "       -2.53306408e+00, -2.88073371e+00, -1.45563861e+00, -2.07629532e+00,\n",
       "       -1.10685887e+00, -3.30746297e+00, -1.70979613e+00,  1.58996274e+00,\n",
       "       -3.52504166e+00, -1.52132704e+00, -1.64646238e+00, -2.48355981e+00,\n",
       "       -1.94542204e+00, -3.83035737e+00,  4.05074905e-01,  1.56887722e+00,\n",
       "       -2.15610384e+00, -3.99607552e+00, -2.33422436e+00, -2.29303782e+00,\n",
       "       -1.54683690e+00, -5.81657121e-01, -2.49388453e+00, -4.46141217e+00,\n",
       "       -2.06159009e+00, -2.37134020e+00, -1.27964995e+00,  2.15268691e+00,\n",
       "       -2.40692701e+00, -3.62409264e+00,  2.26935745e-01, -2.94748477e+00,\n",
       "       -2.69686332e+00, -1.73979814e+00, -3.23192990e+00, -2.28384442e+00,\n",
       "       -2.75296230e+00,  9.46333163e-01, -1.37997218e+00,  7.33829245e-01,\n",
       "        2.36686760e+00, -2.11250101e+00, -1.16846517e+00, -6.85569958e-01,\n",
       "       -1.69766301e+00, -5.58035918e-02, -2.49515108e+00,  4.74839117e-01,\n",
       "       -2.55450898e+00,  1.62323717e+00,  2.16178683e+00, -5.55905779e-01,\n",
       "       -2.17375021e+00,  8.71717022e-01, -6.22630835e-01,  8.67750154e-02,\n",
       "       -2.35013094e+00, -2.86427518e+00, -1.91281750e+00, -2.99443434e+00,\n",
       "       -1.35208685e+00,  2.13145195e+00, -3.08693872e+00, -2.36854157e+00,\n",
       "        1.74678118e+00, -1.79003733e+00, -3.14734680e+00, -3.13537596e+00,\n",
       "       -2.64063999e+00, -2.01534615e+00, -1.61546711e+00, -3.00235003e+00,\n",
       "        3.14245338e+00, -1.67267914e+00,  1.36336289e+00, -2.87844247e+00,\n",
       "       -1.80499842e+00, -1.93414556e+00, -3.53400908e+00, -4.04738960e+00,\n",
       "       -2.30279272e+00,  2.20236618e+00,  7.73784189e-01,  1.36597646e+00,\n",
       "       -2.72847741e+00, -2.54361795e+00, -3.57504502e+00, -2.06341078e+00,\n",
       "       -1.78656807e+00,  7.91114382e-01, -4.24927468e-01, -1.93077940e+00,\n",
       "       -2.56432108e+00, -1.51574705e+00, -2.74750339e+00, -2.50630370e+00,\n",
       "        1.42697572e+00, -2.85912160e+00, -2.86778818e+00, -1.21798547e+00,\n",
       "       -3.80963697e+00, -2.26750407e+00,  1.68138236e+00, -4.21487794e+00,\n",
       "       -2.26607687e+00,  1.46444881e+00, -1.72562590e+00,  9.76504046e-02,\n",
       "        8.51520911e-01,  2.27205104e+00, -1.90408702e+00,  1.58530933e+00,\n",
       "       -2.05286944e+00, -4.26508603e+00,  1.17784092e-01, -2.29827209e+00,\n",
       "       -5.39000303e+00,  1.15222873e+00,  1.89903163e+00, -2.81644557e+00,\n",
       "        2.37698207e-01,  1.06729949e+00,  2.54412097e-01, -2.67526404e-01,\n",
       "        2.16789641e+00, -1.16808575e+00, -2.19909056e+00,  1.03883489e+00,\n",
       "       -3.15335276e+00, -2.43570319e+00,  2.03184896e+00, -6.83467155e-02,\n",
       "       -3.17443827e+00,  1.79046503e+00, -4.16898038e+00, -2.93527907e+00,\n",
       "        2.99339062e-01, -2.74490917e+00,  1.52270759e+00,  2.15996351e+00,\n",
       "       -1.38933914e+00, -9.63997547e-02,  2.04471446e+00, -3.32972442e+00,\n",
       "        1.70954476e+00, -3.25643323e+00, -2.59941263e+00, -4.14787130e-01,\n",
       "       -1.70980354e+00, -2.22892691e+00,  8.86836387e-01,  1.71865696e+00,\n",
       "        8.16300059e-02, -2.96299106e+00, -3.21680851e+00, -2.91568534e+00,\n",
       "        1.45535555e+00, -1.96612736e+00,  1.42311663e+00, -2.62634174e+00,\n",
       "        7.44616938e-01, -2.83403330e+00,  2.91990419e+00, -1.29044499e+00,\n",
       "       -2.54019854e+00, -2.72942279e+00, -1.35707907e+00,  1.91154486e+00,\n",
       "        2.37620632e+00,  1.06302212e+00, -6.82944455e-02, -3.25236828e+00,\n",
       "       -2.42357847e+00,  1.67404329e+00, -2.82634137e+00, -2.70889929e+00,\n",
       "        2.73550663e+00, -7.09430187e-01,  9.98516962e-01, -6.22179770e-01,\n",
       "        2.00598044e+00, -1.06071952e+00, -1.31310637e+00, -1.99601854e+00,\n",
       "        1.70748228e+00, -7.45405231e-01, -1.84335812e-01, -3.54054570e+00,\n",
       "       -1.81335037e+00, -2.45283620e+00,  2.19899483e+00,  1.99635429e+00,\n",
       "       -4.05954149e+00, -1.93205024e+00, -1.70891353e+00,  1.83497663e+00,\n",
       "       -9.14062530e-01, -2.56535487e+00,  6.81711719e-01, -1.81460248e+00,\n",
       "        1.17379511e+00,  1.56854845e+00, -1.09992622e+00, -1.09482506e+00,\n",
       "        1.79565630e+00, -3.01232812e+00, -1.40797014e-01, -1.91383098e+00,\n",
       "       -4.15242262e+00, -3.16242743e+00, -2.66802719e+00,  1.53498944e+00,\n",
       "       -2.43287842e+00, -2.69311993e+00, -2.93671242e+00, -9.52780437e-01,\n",
       "       -2.38878098e+00, -3.74732367e+00,  4.91574091e-01, -2.31159267e+00,\n",
       "       -2.59254351e+00, -2.27549226e+00, -1.57960657e+00, -3.79040686e+00,\n",
       "       -2.20140495e+00, -6.30848599e-01, -4.69850784e+00, -3.72887976e+00,\n",
       "        2.65747952e+00,  1.49583644e+00, -2.95205252e+00, -2.13291347e+00,\n",
       "        3.49546717e-01, -2.76016766e+00, -2.06236664e+00, -1.88222004e+00,\n",
       "       -2.33477831e+00, -3.13558323e+00, -1.43866572e+00,  2.24072197e-01,\n",
       "       -3.55329036e+00,  1.51131976e+00, -1.42040622e+00,  2.22701251e+00,\n",
       "        2.66865058e-02, -5.86152901e-01, -2.92555321e+00, -5.41080020e-01,\n",
       "       -2.90889928e+00, -2.42515659e+00,  2.46148354e+00, -3.13229716e+00,\n",
       "       -2.92023928e+00,  1.62304174e+00, -7.68234155e-01, -1.66862117e+00,\n",
       "        1.60282009e+00, -3.97915424e+00, -1.92112206e+00, -1.14113185e+00,\n",
       "       -2.28762719e+00, -2.27209412e+00, -2.54828997e+00, -6.27979826e-01,\n",
       "        2.87865259e+00, -2.60654887e+00, -1.94396097e+00, -3.57495374e+00,\n",
       "       -2.17888806e+00, -3.34389120e+00,  6.55419326e-01,  2.34354861e+00,\n",
       "       -6.71022595e-02, -3.38912340e+00, -1.45835285e-01, -1.96515241e+00,\n",
       "       -2.87032025e-01, -2.11271188e+00, -3.08527675e+00, -3.01382100e+00,\n",
       "       -2.90696501e+00,  2.45823166e-01, -3.74413688e+00,  1.60015298e+00,\n",
       "        1.42097518e+00, -2.00813906e+00, -3.09623645e+00, -3.64586052e+00,\n",
       "        1.54669669e+00, -2.08411375e-01,  2.00022868e+00, -1.64720069e+00,\n",
       "       -1.24598832e+00, -8.42935541e-01, -1.95976236e+00, -2.94508785e+00,\n",
       "       -1.12512465e+00,  1.91046418e+00,  3.42550158e-01,  1.25402257e+00,\n",
       "        1.38422014e+00, -2.84390800e+00, -3.46385088e+00, -9.74439836e-01,\n",
       "       -3.03489417e+00, -2.86139933e+00, -2.33909088e+00, -2.56128365e+00,\n",
       "       -2.78309706e+00,  5.99906221e-01, -4.10317783e-01, -1.76686184e+00])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Decision_Function(X_cv):\n",
    "    alpha = Classifier.dual_coef_[0]\n",
    "    decision_function = []\n",
    "    \n",
    "    for Xq in X_cv:\n",
    "        sum = Classifier.intercept_[0]\n",
    "        \n",
    "        for i, suprt_vector in enumerate(Classifier.support_vectors_):\n",
    "            norm = np.linalg.norm(suprt_vector - Xq)**2\n",
    "            kernel = np.exp(-0.001 *norm)\n",
    "            sum += (alpha[i] * kernel)\n",
    "        decision_function.append(sum)\n",
    "        \n",
    "    return np.array(decision_function)\n",
    "\n",
    "Decision_Function(X_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Np, Nn = np.unique(y_train, return_counts = True)[1]\n",
    "Yp = (Np + 1) / (Np + 2)\n",
    "Yn = 1 / (Nn + 2)\n",
    "ycv_new = []\n",
    "\n",
    "for y in y_cv:\n",
    "    if y == 0:\n",
    "        ycv_new.append(Yn)\n",
    "    else:\n",
    "        ycv_new.append(Yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(dim).reshape(1,-1)\n",
    "    b = 0\n",
    "\n",
    "    return w,b\n",
    "\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    result = 1/(1+np.exp(-z))\n",
    "    return result\n",
    "\n",
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    loss = -np.sum(y_true * np.log10(y_pred) + (1 - y_true) * np.log10(1 - y_pred))/len(y_true)\n",
    "    return loss\n",
    "\n",
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = (x * (y- sigmoid((w@x)+b) )) - ((alpha/N)*w)\n",
    "    return dw\n",
    "\n",
    "def gradient_db(x,y,w,b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "    db = y - sigmoid(w@x+b)\n",
    "    return db\n",
    "\n",
    "def train(X_train,y_train,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    train_loss,test_loss = [],[]\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    #print(\"weight is {}\".format(b))\n",
    "\n",
    "    N = len(X_train)\n",
    "    for epoch in tqdm(range(0,epochs)):\n",
    "        for x,y in zip(X_train.reshape(-1,1),y_train.reshape(-1,1)):\n",
    "            #print(x.shape)\n",
    "            #print(y.shape)\n",
    "            #print(w.shape)\n",
    "            #print(b)\n",
    "            gradw = gradient_dw(x,y,w,b,alpha,N)\n",
    "            gradb = gradient_db(x,y,w,b)\n",
    "            w += (eta0 * gradw)\n",
    "            b += (eta0 * gradb)\n",
    "       \n",
    "        trainloss = logloss(y_train, 1/(1+np.exp(-(w * Decision_Function(X_train) + b))))\n",
    "        train_loss.append(trainloss)\n",
    "        print(f\"Epoch {epoch+1}: Training loss: {trainloss}\")\n",
    "                \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                 | 1/50 [00:12<09:53, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training loss: 0.29912812050652676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                               | 2/50 [00:25<09:57, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training loss: 0.2973189400087711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▉                                                                              | 3/50 [00:36<09:32, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training loss: 0.29559790787495865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 4/50 [00:48<09:10, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training loss: 0.2939606863985513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 5/50 [01:00<08:54, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training loss: 0.29240313955236735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▉                                                                         | 6/50 [01:12<08:52, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training loss: 0.2909213259185209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▌                                                                       | 7/50 [01:25<08:43, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training loss: 0.2895114915260233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 8/50 [01:37<08:29, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training loss: 0.2881700626548094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                    | 9/50 [01:48<08:13, 12.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training loss: 0.28689363865663553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 10/50 [02:00<08:02, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training loss: 0.28567898483576337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████                                                                | 11/50 [02:13<07:52, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training loss: 0.2845230254255434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▋                                                              | 12/50 [02:24<07:33, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training loss: 0.2834228366909355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▎                                                            | 13/50 [02:36<07:22, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training loss: 0.28237564018157707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▉                                                           | 14/50 [02:48<07:10, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Training loss: 0.281378796155221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 15/50 [03:00<07:00, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training loss: 0.2804297971871343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▏                                                       | 16/50 [03:13<06:53, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training loss: 0.2795262619773572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▉                                                      | 17/50 [03:24<06:33, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training loss: 0.2786659293645021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▌                                                    | 18/50 [03:37<06:25, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training loss: 0.2778466525519916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▏                                                  | 19/50 [03:49<06:13, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training loss: 0.27706639355024404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 20/50 [04:01<06:03, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training loss: 0.276323217836273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▍                                               | 21/50 [04:14<05:56, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Training loss: 0.27561528923044615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                              | 22/50 [04:25<05:40, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training loss: 0.2749408649886942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▋                                            | 23/50 [04:38<05:28, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training loss: 0.2742982911072613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                          | 24/50 [04:49<05:12, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training loss: 0.2736859978360993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 25/50 [05:02<05:02, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Training loss: 0.27310249539621134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▋                                       | 26/50 [05:13<04:47, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training loss: 0.27254636989561215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████████████████████████████████████▎                                     | 27/50 [05:26<04:40, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training loss: 0.2720162794380887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▉                                    | 28/50 [05:38<04:27, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training loss: 0.2715109504185693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████████████████████████████▌                                  | 29/50 [05:51<04:17, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Training loss: 0.27102917399865295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 30/50 [06:03<04:05, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Training loss: 0.27056980275567427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████▊                               | 31/50 [06:15<03:52, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Training loss: 0.2701317474985907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▍                             | 32/50 [06:27<03:40, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training loss: 0.2697139742439407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████████                            | 33/50 [06:40<03:27, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training loss: 0.2693155013451517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▊                          | 34/50 [06:51<03:13, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training loss: 0.26893539676854017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 35/50 [07:03<03:01, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training loss: 0.2685727755094549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████                       | 36/50 [07:16<02:50, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training loss: 0.26822679714214626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▋                     | 37/50 [07:28<02:36, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Training loss: 0.26789666349710456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 38/50 [07:39<02:23, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Training loss: 0.2675816164597847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▉                  | 39/50 [07:51<02:09, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Training loss: 0.2672809358848299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 40/50 [08:02<01:55, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Training loss: 0.26699393762010143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████▏              | 41/50 [08:13<01:43, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Training loss: 0.2667199716350338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 42/50 [08:24<01:31, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Training loss: 0.26645842024804367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████▌           | 43/50 [08:35<01:19, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Training loss: 0.2662086964479353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 44/50 [08:47<01:08, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training loss: 0.2659702423044605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 45/50 [08:58<00:56, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Training loss: 0.26574252746339605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 46/50 [09:11<00:46, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Training loss: 0.2655250477217197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████████████     | 47/50 [09:22<00:34, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training loss: 0.26531732367866184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 48/50 [09:33<00:22, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training loss: 0.26511889945861394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████▎ | 49/50 [09:44<00:11, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Training loss: 0.26492934150206876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [09:56<00:00, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Training loss: 0.26474823742095405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wgt, bias = train(np.array(ycv_new), y_cv, 50, 0.0001, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00068101]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(w, b, X):\n",
    "    #N = len(X)\n",
    "    predict = []\n",
    "    for i in range(len(X)):\n",
    "        z = np.multiply(w, X[i]) + b\n",
    "        A = sigmoid(z)\n",
    "    for j in range(len(X)):\n",
    "        if A.any >= 0.5:\n",
    "            print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'builtin_function_or_method' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-fe1fc60b4d2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-92-e711871e07d3>\u001b[0m in \u001b[0;36mPredict\u001b[1;34m(w, b, X)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'builtin_function_or_method' and 'float'"
     ]
    }
   ],
   "source": [
    "Predict(wgt, bias, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-8ab89112d4eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwgt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-482fecbc4790>\u001b[0m in \u001b[0;36mPredict\u001b[1;34m(w, b, X)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "print(1-np.sum(Y_train - Predict(wgt, bias, x_train)) / len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E&F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
